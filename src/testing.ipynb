{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
add    "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'HMC_new'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mHMC_new\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HMC\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'HMC_new'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from HMC import HMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating basic keras model\n",
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(4,)),\n",
    "    # keras.layers.Dense(8, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L1(1)),\n",
    "    keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.L1(0.1), use_bias=False)\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-2),\n",
    "              loss=keras.losses.MeanSquaredError())\n",
    "keras.utils.plot_model(model, show_shapes=True, to_file=\"../etc/test.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# creating fake data\n",
    "t = np.linspace(-3.14, 3.14, 50)\n",
    "x = np.stack([\n",
    "    t ** 2,\n",
    "    t,\n",
    "    np.cos(t),\n",
    "    - t ** 3\n",
    "]).T + 0 * np.random.randn(50, 4)\n",
    "y = np.expand_dims(t, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model pre-training\n",
    "model.fit(x, y, epochs=500)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot fitted prediction and model pre-trained parameters\n",
    "fig = plt.figure()\n",
    "plt.plot(t, y, 'b-')\n",
    "plt.plot(t, model(x), 'r-')\n",
    "plt.show()\n",
    "model.trainable_variables"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create HMC super-model\n",
    "hmc = HMC(model, L=10, epsilon=1e-2, batch_size=50)\n",
    "\n",
    "# Initialize bookkeeping\n",
    "n_iter = 2000\n",
    "parameters = np.zeros((n_iter, hmc.param_num), dtype=np.float32)  # bookkeeping the parameters\n",
    "log_gamma = np.zeros((n_iter,), dtype=np.float32)  # bookkeeping the loggamma\n",
    "log_lambda = np.zeros((n_iter,), dtype=np.float32)  # bookkeeping the loggamma\n",
    "log_likelihood = np.zeros((n_iter,), dtype=np.float32)  # bookkeeping the loggamma\n",
    "hamiltonians = np.zeros((n_iter,), dtype=np.float32)\n",
    "acceptance = np.zeros((n_iter,), dtype=np.float32)\n",
    "\n",
    "# training loop\n",
    "for step in range(n_iter):\n",
    "    new_state, loss, p, accepted, h = hmc((x, y))\n",
    "    # print(f\"Step {step}: \")\n",
    "    if accepted:\n",
    "        acceptance[step] = 1\n",
    "        # print(f\"New state accepted with probability {p}\")\n",
    "    # else:\n",
    "    # print(f\"New state rejected with probability {p}\")\n",
    "\n",
    "    # bookkeeping\n",
    "    parameters[step, :] = new_state.position\n",
    "    log_gamma[step] = new_state.log_gamma\n",
    "    log_lambda[step] = new_state.log_lambda\n",
    "    log_likelihood[step] = loss\n",
    "    hamiltonians[step] = h"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Computing MAP estimate\n",
    "idx_MAP = np.argmin(log_likelihood)\n",
    "MAP = parameters[idx_MAP, :]\n",
    "hmc.set_model_params(MAP)\n",
    "y_MAP = hmc.model(x)\n",
    "\n",
    "# preparing sampling\n",
    "precision = np.exp(log_gamma)\n",
    "num_dim = 1\n",
    "n_samples = 500\n",
    "trajectories = np.zeros((50, num_dim, n_samples))\n",
    "sigma_normal = np.std(y)\n",
    "\n",
    "# sampling\n",
    "for k in range(n_samples):\n",
    "    idx_1 = np.random.randint(0, n_iter - 1)\n",
    "    idx_2 = np.random.randint(0, n_iter - 1)\n",
    "    w_sample = parameters[-idx_1, :]\n",
    "    precision_here = precision[-idx_2] * num_dim\n",
    "    hmc.set_model_params(w_sample)\n",
    "    trajectories[:, :, k] = hmc.model(x) + sigma_normal * np.random.normal() / np.sqrt(precision_here)\n",
    "\n",
    "mu_pred = np.mean(trajectories, axis=2)\n",
    "sigma_pred = np.var(trajectories, axis=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot results and display MAP parameters\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(t, y, 'ro', label=\"training data\")\n",
    "plt.plot(t, y, 'b-', label=\"true value\")\n",
    "plt.plot(t, y_MAP, label=\"MAP estimate\")\n",
    "plt.plot(t, mu_pred, label=\"Avg estimate\")\n",
    "lower = mu_pred[:, 0] - 2 * np.sqrt(sigma_pred[:, 0])\n",
    "upper = mu_pred[:, 0] + 2 * np.sqrt(sigma_pred[:, 0])\n",
    "plt.fill_between(t, lower, upper, facecolor=\"orange\", alpha=0.5, label=\"Two std band\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "MAP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot Hamiltonian variation through trajectory (approximately constant in theory)\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(range(hamiltonians.size), hamiltonians)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot parameters spread\n",
    "fig, axs = plt.subplots(4, 4, figsize=(15, 15))\n",
    "for i in range(4):\n",
    "    axs[i, i].hist(parameters[:, i], bins=30, density=True)\n",
    "    for j in range(i):\n",
    "        axs[i, j].scatter(parameters[:, j], parameters[:, i], s=1, marker=\"+\")\n",
    "    for j in range(i + 1, 4):\n",
    "        axs[i, j].hist2d(parameters[:, j], parameters[:, i], bins=30, cmap=\"Blues\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}